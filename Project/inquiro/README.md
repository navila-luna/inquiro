# Inquiro

A knowledge base search application that extracts Q&A pairs from email threads and provides intelligent search capabilities.

## Getting Started

First, run the development server:

```bash
npm run dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

## Database Seeding

This project includes an enhanced database seeding script that populates PostgreSQL and Pinecone with email data and knowledge pairs. The seeding system now supports incremental updates and prevents duplicates.

### Seeding Modes

#### 1. Incremental Mode (Default)
Processes new threads each time, building a diverse knowledge base over time:
```bash
npm run db:seed
```
- âœ… **Preserves existing data**
- âœ… **Processes 5 new threads per run**
- âœ… **Prevents duplicate knowledge pairs**
- âœ… **Respects API rate limits**
- âœ… **Builds variety over time**

#### 2. Force Reset Mode
Clears all existing data and starts fresh:
```bash
npm run db:seed:force
```
- ğŸ—‘ï¸ **Clears all existing data**
- ğŸ†• **Processes first 5 threads**
- ğŸ”„ **Complete fresh start**

#### 3. Reprocess Mode
Reprocesses threads to extract new knowledge (useful when LLM extracts different insights):
```bash
npm run db:seed:reprocess
```
- ğŸ”„ **Reprocesses existing threads**
- ğŸ§  **LLM might extract different knowledge**
- âœ… **Prevents duplicate knowledge pairs**
- ğŸ“Š **Builds additional knowledge from same threads**

#### 4. Mock Mode (Skips Gemini API)
Uses predefined mock data without consuming API quota:
```bash
npm run db:seed:mock
```

#### 5. Local Mode (Skips All External APIs)
Tests only PostgreSQL operations (fastest for development):
```bash
npm run db:seed:local
```

### Environment Variables

Control specific operations with environment variables:
```bash
# Skip Gemini API calls
SKIP_API_CALLS=true npm run db:seed

# Skip Pinecone operations
SKIP_PINECONE=true npm run db:seed

# Skip both APIs (same as local mode)
SKIP_API_CALLS=true SKIP_PINECONE=true npm run db:seed
```

### Enhanced Features

#### Incremental Seeding
- **Smart thread selection**: Automatically picks unprocessed threads
- **Duplicate prevention**: Checks for existing knowledge pairs before adding
- **Variety building**: Different knowledge each time you seed
- **Progress tracking**: Shows exactly what was added

#### Rate Limiting
- **API quota management**: Processes 5 threads per run
- **4-second delays**: Between API calls to respect limits
- **Batch processing**: Efficient handling of multiple threads

#### Detailed Logging
```
ğŸ” Checking for duplicate knowledge (15 existing pairs)
âœ… Adding new knowledge: "Is the cost of a new office espresso machine..."
âš ï¸ Skipping duplicate: "What documentation do I need for business..."
ğŸ“Š Summary: Added 2 new knowledge pairs (17 total)
```

### When to Use Each Mode

| Mode | Use Case | Data Impact |
|------|----------|-------------|
| `npm run db:seed` | Normal development | Incremental, preserves existing |
| `npm run db:seed:force` | Fresh start needed | Clears everything |
| `npm run db:seed:reprocess` | Extract new knowledge from existing threads | Reprocesses, prevents duplicates |
| `npm run db:seed:mock` | Testing without API costs | Uses mock data |
| `npm run db:seed:local` | Fast development testing | PostgreSQL only |

### Handling Edge Cases

#### Fewer Than 5 Threads Available
When you've processed most threads, you might have fewer than 5 available:
- âœ… **Automatic handling**: Processes all available threads
- âš ï¸ **Warning message**: Alerts you when fewer than 5 threads remain
- ğŸ’¡ **Suggestions**: Recommends FORCE_RESET or REPROCESS options

#### Threads That Might Produce New Information
Even processed threads can yield new knowledge:
- ğŸ”„ **Reprocess mode**: `npm run db:seed:reprocess`
- ğŸ§  **LLM variability**: Different insights each time
- âœ… **Duplicate prevention**: Still prevents exact duplicates
- ğŸ“Š **Additional knowledge**: Builds on existing knowledge base

**Note**: The incremental mode is perfect for building a diverse knowledge base over time while respecting API quotas and preventing duplicates.